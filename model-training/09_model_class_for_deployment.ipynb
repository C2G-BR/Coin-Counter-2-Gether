{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoxPA8Uoow_m"
      },
      "source": [
        "# Development of the model class that will be used for the backend\n",
        "\n",
        "This notebook is intended for testing and experimentation purposes only. Here the classes for the backend are written, which are used in the PROD environment.\n",
        "Since minor changes were made directly in the server script, there are consequently deviations from this script here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc0O6QbloRe9"
      },
      "source": [
        "\n",
        "\n",
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZgOTEtl0hrS",
        "outputId": "1738d385-f956-4c2f-f25d-8cbb2c7cb82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jqzv-E50-_4",
        "outputId": "68fec766-5f21-4659-c2fc-ff3e390c9fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: albumentations 0.1.12\n",
            "Uninstalling albumentations-0.1.12:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/albumentations-0.1.12.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/albumentations/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled albumentations-0.1.12\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 231 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 2.3 MB/s \n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall albumentations\n",
        "!pip install -qU torch_snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcyvoUvW1CF0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_snippets import *\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import os \n",
        "from torchvision.ops import nms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6ryYXyI106h"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/drive/MyDrive/outputs/models/faster_rcnn_mobilenetv3_large.pt'\n",
        "rootdir = '/content/drive/MyDrive/data'\n",
        "image_path = '/content/drive/MyDrive/data/euro-coin-dataset'\n",
        "df_test = pd.read_csv(os.path.join(rootdir, 'test.csv'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zas5g3t1WFm"
      },
      "outputs": [],
      "source": [
        "# Parses and processes image\n",
        "\n",
        "class Pipeline():\n",
        "    def __init__(self, device, target_width = 504, target_height = 504):\n",
        "        self.target_width = target_width\n",
        "        self.target_height = target_height\n",
        "        self.device = device\n",
        "\n",
        "    def image_to_tensor(self, img):\n",
        "        img = torch.tensor(img).permute(2,0,1)\n",
        "        return img.to(self.device).float()\n",
        "    \n",
        "    def preprocess_image(self, img):\n",
        "        img = np.array(img.resize((self.target_width, self.target_height), resample=Image.BILINEAR))/255.\n",
        "        return img\n",
        "\n",
        "    def pipe(self, image):\n",
        "        \"\"\"\n",
        "        image: PIL.Image --> convert('RGB')\n",
        "        \"\"\"\n",
        "        image = self.preprocess_image(image)\n",
        "        image = self.image_to_tensor(image)\n",
        "        return image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1canJlHq1ZbH",
        "outputId": "00c76edc-343d-4152-f578-0682de0bde8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished initializing CoinDetector\n"
          ]
        }
      ],
      "source": [
        "ima = None\n",
        "class CoinDetector():\n",
        "    def __init__(self, model_path, target2label, threshold = None):\n",
        "        \n",
        "        self.num_classes = len(target2label)\n",
        "        self.target2label = target2label\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # read model\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=False)\n",
        "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, self.num_classes)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # create pipeline\n",
        "        self.pipeline = Pipeline(self.device)\n",
        "\n",
        "\n",
        "        print('Finished initializing CoinDetector')\n",
        "\n",
        "    def calculate_coin_value(labels, confs, threshold = None, size = None):\n",
        "        coin_value = 0\n",
        "        if threshold is None:\n",
        "            threshold = 0\n",
        "        for ix, label in enumerate(labels):\n",
        "            if confs[ix] > threshold:\n",
        "                coin_value += label\n",
        "        return coin_value\n",
        "\n",
        "    def decode_output(self, output, normalize_bbs = True, size = None):\n",
        "        'convert tensors to numpy arrays'\n",
        "        bbs = output['boxes'].cpu().detach().numpy().astype(np.uint16)\n",
        "        labels = np.array([self.target2label[i] for i in output['labels'].cpu().detach().numpy()])\n",
        "        confs = output['scores'].cpu().detach().numpy()\n",
        "        ixs = nms(torch.tensor(bbs.astype(np.float32)), torch.tensor(confs), 0.05)\n",
        "        bbs, confs, labels = [tensor[ixs] for tensor in [bbs, confs, labels]]\n",
        "        print(type(bbs))\n",
        "        if normalize_bbs and size is not None:\n",
        "          print(bbs)\n",
        "          bbs = bbs.astype(float)\n",
        "          width, height = size\n",
        "          bbs[:, [0, 2]] = bbs[:, [0, 2]] / width\n",
        "          bbs[:, [1, 3]] = bbs[:, [1, 3]] / height\n",
        "          print(bbs)\n",
        "\n",
        "        if len(ixs) == 1:\n",
        "            bbs, confs, labels = [np.array([tensor]) for tensor in [bbs, confs, labels]]\n",
        "        return bbs.tolist(), confs.tolist(), labels.tolist()\n",
        "\n",
        "    def predict(self, img):\n",
        "        global ima\n",
        "   \n",
        "        img = self.pipeline.pipe(img)\n",
        "        width, height = img.shape[1:]\n",
        "        print(width, height)\n",
        "        ima = img\n",
        "        \n",
        "        img = [img]\n",
        "\n",
        "        self.model.eval()\n",
        "        outputs = self.model(img)\n",
        "        for ix, output in enumerate(outputs):\n",
        "            bbs, confs, labels = self.decode_output(output, size=(width, height))\n",
        "            print(bbs)\n",
        "            \n",
        "            info = [f'{l}@{c:.2f}' for l,c in zip(labels, confs)]\n",
        "            print(info)\n",
        "            # show(img[ix].cpu().permute(1,2,0), bbs=bbs, texts=info, sz=5 )\n",
        "            coin_value = CoinDetector.calculate_coin_value(labels, confs, threshold = self.threshold)\n",
        "            return coin_value\n",
        "\n",
        "target2label = {1: 1, 2: 10, 3: 100, 4: 2, 5: 20, 6: 200, 7: 5, 8: 50, 0: 'background'}\n",
        "cd = CoinDetector(model_path=model_path, target2label=target2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh7KuJRO2lXM",
        "outputId": "ed576004-3a15-475d-9109-246b1f3ae19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "(3024, 3024)\n",
            "504 504\n",
            "<class 'numpy.ndarray'>\n",
            "[[285  46 391 156]\n",
            " [190 197 297 310]\n",
            " [346 178 455 286]\n",
            " [116  44 231 157]\n",
            " [270 314 375 411]\n",
            " [ 47 169 146 272]\n",
            " [ 85 321 197 427]]\n",
            "[[0.56547619 0.09126984 0.77579365 0.30952381]\n",
            " [0.37698413 0.39087302 0.58928571 0.61507937]\n",
            " [0.68650794 0.3531746  0.90277778 0.56746032]\n",
            " [0.23015873 0.08730159 0.45833333 0.31150794]\n",
            " [0.53571429 0.62301587 0.74404762 0.81547619]\n",
            " [0.09325397 0.33531746 0.28968254 0.53968254]\n",
            " [0.16865079 0.63690476 0.39087302 0.84722222]]\n",
            "[[0.5654761904761905, 0.09126984126984126, 0.7757936507936508, 0.30952380952380953], [0.376984126984127, 0.39087301587301587, 0.5892857142857143, 0.6150793650793651], [0.6865079365079365, 0.3531746031746032, 0.9027777777777778, 0.5674603174603174], [0.23015873015873015, 0.0873015873015873, 0.4583333333333333, 0.3115079365079365], [0.5357142857142857, 0.623015873015873, 0.7440476190476191, 0.8154761904761905], [0.09325396825396826, 0.3353174603174603, 0.2896825396825397, 0.5396825396825397], [0.16865079365079366, 0.6369047619047619, 0.39087301587301587, 0.8472222222222222]]\n",
            "['50@0.27', '50@0.26', '50@0.25', '50@0.25', '50@0.25', '50@0.25', '50@0.24']\n",
            "==========\n",
            "Actuals:\t 7\n",
            "Calculated:\t 350\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "# Test case\n",
        "\n",
        "for ix, fn in enumerate(df_test['filename'].head(200).unique()):\n",
        "  if ix == 1:\n",
        "    break\n",
        "\n",
        "  try:\n",
        "    data = df_test[df_test['filename'] == fn]\n",
        "    folder = data['folder'].values[0]\n",
        "    filepath = os.path.join(image_path, folder, fn)\n",
        "    img = Image.open(filepath)\n",
        "    img = img.transpose(Image.ROTATE_270)\n",
        "\n",
        "    print(type(img)) #0-255\n",
        "    print(img.size)\n",
        "\n",
        "    value = cd.predict(img)\n",
        "    print('='*10)\n",
        "    print(f\"Actuals:\\t {data['pose'].sum()}\")\n",
        "    print(f'Calculated:\\t {value}')\n",
        "    print('='*10)\n",
        "  except Exception as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ModelClassForDeployment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
